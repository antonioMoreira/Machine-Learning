{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pe-lLjBpQ8xy"
   },
   "source": [
    "# PolynomialFeatures\n",
    "\n",
    "Como a documentação do sklearn não estava muito clara, achei melhor esclarecer como funciona a regressão polinomial.\n",
    "\n",
    "Suponha que temos uma base de dados $D$ que possui variáveis de nome $A, B$ e valor de função $T$. Uma observação dessas variáveis é dada por $(a_0, b_0)$, com valor $t_0$. \n",
    "\n",
    "\n",
    "* Uma aproximação linear de $t_0$ (suponha que os valores  $\\beta_i$ foram encontrados utilizando algum algoritmo como mínimos quadrados) pode ser dada por:\n",
    "\n",
    "  $t^{(1)}_0=f^{(1)}(a_0, b_0)= \\beta^{(1)}_0 + \\beta^{(1)}_1 a_0 + \\beta^{(1)}_2 b_0 $\n",
    "\n",
    "* Uma aproximação quadrática (polinômio de segundo grau) da função pode ser vista da forma:\n",
    "\n",
    "  $t^{(2)}_0=f^{(2)}(a_0, b_0)= \\beta^{(2)}_0 + \\beta^{(2)}_1 a_0 + \\beta^{(2)}_2 b_0 + \\beta^{(2)}_4 a_0^2 + \\beta^{(2)}_5 b_0^2 + \\beta^{(2)}_7 a_0 b_0$\n",
    "\n",
    "* Note que podemos encarar \"aproximar via função quadrática\" como \"aproximar via função linear\" se considerarmos $a_0^2$, $b_0^2$ e $a_0b_0$ como novas variáveis, $c_0, d_0$ e $e_0$ no problema:\n",
    "\n",
    "  $t^{(3)}_0=f^{(3)}(a_0, b_0, c_0, d_0, e_0)= \\beta^{(3)}_0 + \\beta^{(3)}_1 a_0 + \\beta^{(3)}_2 b_0 + \\beta^{(3)}_3 c_0 + \\beta^{(3)}_4 d_0 + \\beta^{(3)}_5 e_0$\n",
    "\n",
    "* Basta que realizemos a transformação de $(a, b)$ para $(a, b, c, d, e)$, com $c=a^2, d=b^2$ e $e=ab$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Felizmente a classe **PolynomialFeatures** é bastante útil nesse momento, pois ela nos permite realizar essa transformação facilmente, de forma que consigamos utilizar a mesma sintaxe utilizado anteriormente para adaptar nosso modelo linear.\n",
    "\n",
    "Basta inicializar um polinômio e transformar o conjunto de dados, por exemplo:\n",
    "\n",
    "```python\n",
    "p = PolynomialFeatures(degree=grau)\n",
    "X_Transf = p.fit_transform(X)\n",
    "```\n",
    "\n",
    "E agora ao invés de adaptar nosso modelo linear ao conjunto X, adaptamos ao conjunto X_Transf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1551963721614,
     "user": {
      "displayName": "Felipe Padula Sanches",
      "photoUrl": "https://lh4.googleusercontent.com/-nernBhYcW4o/AAAAAAAAAAI/AAAAAAAANRw/LcF4_Q1FmN8/s64/photo.jpg",
      "userId": "18187017750627346096"
     },
     "user_tz": 180
    },
    "id": "iI0gl-e6OWML",
    "outputId": "6e995b1e-90d5-4f07-d134-224a8c31cd81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'x0', 'x0^2', 'x0^3']\n",
      "[[1. 2. 4. 8.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([2]).reshape(1, -1)\n",
    "p = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_Transf = p.fit_transform(x)\n",
    "print(p.get_feature_names())\n",
    "print(X_Transf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Funcionamento PolynomialFeatures.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "DS_ML",
   "language": "python",
   "name": "ds_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
